import asyncio
import logging
import time
import jwt
import pytest
from unittest.mock import AsyncMock, MagicMock, patch, call
from prometheus_client import Counter

# === Test edilen modÃ¼l ve bileÅŸenler ===
from learning import (
    validate_file_path, check_user_authorization, chunk_text,
    RedisRateLimiter, learn_from_text, celery_summarize_and_save,
    get_tokenizer, get_summarizer, learn_from_pdf, learn_from_docx,
    learn_from_url, celery_audio_to_text_and_save, rate_limiter,
    redis_client, learning_calls_total
)
from core.metrics import LEARN_COUNTER, LEARN_ERROR_COUNTER, metrics

# === Otomatik sayaÃ§ sÄ±fÄ±rlama ===
@pytest.fixture(autouse=True)
def reset_counters():
    """
    Her testten Ã¶nce LEARN_COUNTER ve LEARN_ERROR_COUNTER sayaÃ§larÄ±nÄ± sÄ±fÄ±rlar.
    Bu sayede testler birbirinden baÄŸÄ±msÄ±z metrik sonuÃ§larÄ±yla Ã§alÄ±ÅŸÄ±r.
    """
    LEARN_COUNTER._value.set(0)
    LEARN_ERROR_COUNTER._value.set(0)
    yield


# === Sabit tanÄ±mlar (JWT, logger, metrik) ===
JWT_SECRET = "testsecret"
JWT_ALGORITHM = "HS256"

# Ã–rnek bir metrik sayaÃ§ tanÄ±mÄ± (test iÃ§inde kullanÄ±lacak)
learning_calls_total = Counter('learning_calls_total', 'Total learning calls')

# Logger yapÄ±landÄ±rmasÄ±
logger = logging.getLogger(__name__)


# === METRIK / MONITORING TESTLERÄ° ===

@pytest.mark.asyncio
async def test_learn_from_text_metric_on_tokenizer_failure():
    """
    Tokenizer hatasÄ±nda LEARN_ERROR_COUNTER artÄ±ÅŸÄ±nÄ± test eder.
    """
    initial = LEARN_ERROR_COUNTER._value.get()

    with patch("learning.chunk_text", return_value=["chunk"]), \
         patch("learning.get_tokenizer", side_effect=RuntimeError("tokenizer failed")):

        with pytest.raises(RuntimeError):
            await learn_from_text("Ã¶rnek metin")

    assert LEARN_ERROR_COUNTER._value.get() == initial + 1


@pytest.mark.asyncio
async def test_learn_from_text_metric_on_success():
    """
    Metin baÅŸarÄ±yla iÅŸlendiÄŸinde LEARN_COUNTER artÄ±ÅŸÄ±nÄ± test eder.
    """
    initial = LEARN_COUNTER._value.get()

    with patch("learning.chunk_text", return_value=["chunk"]), \
         patch("learning.get_tokenizer"), \
         patch("learning.get_summarizer"), \
         patch("learning.celery_summarize_and_save.delay"):

        await learn_from_text("Ã¶rnek metin")

    assert LEARN_COUNTER._value.get() == initial + 1


@pytest.mark.asyncio
async def test_learn_from_text_metric_on_chunking_failure():
    """
    chunk_text baÅŸarÄ±sÄ±z olduÄŸunda LEARN_ERROR_COUNTER artÄ±ÅŸÄ±nÄ± test eder.
    """
    initial = LEARN_ERROR_COUNTER._value.get()

    with patch("learning.chunk_text", side_effect=ValueError("chunk failed")):
        with pytest.raises(ValueError, match="chunk failed"):
            await learn_from_text("deneme metin")

    assert LEARN_ERROR_COUNTER._value.get() == initial + 1


def test_learning_metric_increments(monkeypatch):
    """
    Metric sayaÃ§larÄ±nÄ±n elle artÄ±rÄ±lmasÄ± test edilir.
    learning_calls_total metriÄŸi testte manuel olarak artÄ±rÄ±lÄ±r.
    """
    initial_count = learning_calls_total._value.get()

    # save_memory fonksiyonu yerine metrik artÄ±ran mock fonksiyonu kullan
    async def mock_save(*args, **kwargs):
        learning_calls_total.inc()

    monkeypatch.setattr("learning.save_memory", mock_save)

    import asyncio
    asyncio.run(learning.learn_from_text("user_metric", "metin"))

    assert learning_calls_total._value.get() == initial_count + 1


@pytest.mark.asyncio
@patch("core.metrics.metrics.learn_request_counter.inc")
async def test_learn_metric_increment(mock_inc):
    """
    learn_request_counter metriÄŸinin artÄ±p artmadÄ±ÄŸÄ±nÄ± test eder.
    """
    await learn_from_text("Metric test")
    mock_inc.assert_called_once()


# === EDGE CASE TESTLERÄ° ===

def test_validate_file_path_too_small(tmp_path):
    """
    Ã‡ok kÃ¼Ã§Ã¼k dosyalarÄ±n (Ã¶rneÄŸin 0 byte) geÃ§ersiz sayÄ±ldÄ±ÄŸÄ±nÄ± test eder.
    """
    test_file = tmp_path / "empty.txt"
    test_file.write_bytes(b"")  # 0 byte dosya oluÅŸtur
    assert not validate_file_path(str(test_file), min_size_mb=0.1)

@pytest.mark.asyncio
@patch("learning.aiohttp.ClientSession.get")
async def test_learn_from_url_very_long_url(mock_get):
    """
    AÅŸÄ±rÄ± uzun URL'lerin de iÅŸlenebilir olduÄŸunu doÄŸrular.
    """
    class MockResponse:
        status = 200
        async def text(self):
            return "<html><body><p>Ä°Ã§erik</p></body></html>"

        async def __aenter__(self): return self
        async def __aexit__(self, exc_type, exc, tb): pass

    mock_get.return_value = MockResponse()
    long_url = "http://example.com/" + ("a" * 5000)
    await learn_from_url("user_longurl", long_url)

@pytest.mark.parametrize("text, expected_chunks", [
    ("", 0),  # BoÅŸ metin
    ("A" * 100000, pytest.approx(100000 / 512, rel=0.5)),  # Ã‡ok uzun metin
    ("\u202e" * 1024, 1),  # Unicode kontrol karakterleri
])
def test_chunk_text_boundaries(text, expected_chunks):
    """
    chunk_text fonksiyonunun sÄ±nÄ±r koÅŸullarÄ±ndaki davranÄ±ÅŸÄ±nÄ± test eder.
    """
    chunks = chunk_text(text)
    if isinstance(expected_chunks, (int, float)):
        assert len(chunks) == pytest.approx(expected_chunks, rel=0.5)
    else:
        assert len(chunks) == expected_chunks

def test_chunk_text_edge_cases():
    """
    chunk_text fonksiyonunun boÅŸ, kÄ±sa, Ã§ok uzun ve Ã¶zel karakter iÃ§eren metinlerdeki davranÄ±ÅŸÄ±nÄ± test eder.
    """
    # BoÅŸ metin
    assert chunk_text("") == []

    # Ã‡ok kÄ±sa metin
    short_text = "Merhaba."
    chunks = chunk_text(short_text, max_tokens=10)
    assert chunks == [short_text]

    # Ã‡ok uzun metin
    long_text = "kelime " * 1000
    chunks = chunk_text(long_text, max_tokens=50)
    assert len(chunks) > 10

    # Ã–zel karakter ve emoji iÃ§eren metin
    special_text = "Ã§alÄ±ÅŸma ğŸ˜Š test â€” hÄ±zlÄ± & doÄŸru."
    chunks = chunk_text(special_text, max_tokens=10)
    assert any("ğŸ˜Š" in chunk for chunk in chunks)

def test_advanced_content_filter_edge_cases():
    """
    FarklÄ± spam iÃ§erik varyasyonlarÄ±nÄ±n iÃ§erik filtresinden geÃ§ip geÃ§mediÄŸini test eder.
    """
    spam_texts = [
        "This is a SpamWord1 attempt",
        "Beware of phishing attacks!",
        "MALWARE detected inside.",
        "Possible Hack attempt",
        "No bad content here."
    ]
    results = [advanced_content_filter(text) for text in spam_texts]
    assert results == [False, False, False, False, True]

def test_rate_limiter_edge_cases(monkeypatch):
    """
    Redis baÄŸlantÄ±sÄ±nÄ±n olmamasÄ± veya hata vermesi durumunda rate limiter'Ä±n izin vermeye devam etmesini doÄŸrular.
    """
    limiter = RedisRateLimiter("test_rate", rate=3, per=2)

    # Redis client yoksa True dÃ¶nmeli
    monkeypatch.setattr("learning.redis_client", None)
    assert limiter.allow("userX")

    # Redis pipeline hata verirse yine True dÃ¶nmeli
    mock_redis = MagicMock()
    mock_redis.pipeline.side_effect = Exception("Redis hata")
    monkeypatch.setattr("learning.redis_client", mock_redis)
    assert limiter.allow("userX")

@pytest.mark.asyncio
async def test_cache_ttl_expiry(monkeypatch):
    """
    Redis cache'teki TTL sÃ¼resi dolduÄŸunda anahtarÄ±n silindiÄŸini test eder.
    """
    test_user = "user1"
    test_text = "cache test metni"
    test_hash = "abc123"
    
    monkeypatch.setattr("learning.redis_client", redis_client)

    # AnahtarÄ± 1 saniyelik TTL ile ayarla
    redis_client.setex(f"text_cache:{test_user}:{test_hash}", 1, "1")
    assert redis_client.exists(f"text_cache:{test_user}:{test_hash}") == 1

    # TTL dolduktan sonra anahtar silinmiÅŸ olmalÄ±
    await asyncio.sleep(2)
    assert redis_client.exists(f"text_cache:{test_user}:{test_hash}") == 0

logger = logging.getLogger("learning")


# ==============================
#          PERFORMANS TESTLERÄ°
# ==============================

@pytest.mark.benchmark(group="chunk_text")
def test_chunk_text_performance(benchmark):
    """
    chunk_text fonksiyonunun performansÄ±nÄ± test eder.
    
    Bu test, verilen metni tokenize edip parÃ§alara ayÄ±rma iÅŸleminin
    ne kadar sÃ¼rede tamamlandÄ±ÄŸÄ±nÄ± Ã¶lÃ§er.
    """
    text = "kelime " * 500
    benchmark(lambda: chunk_text(text, max_tokens=50))


@pytest.mark.benchmark(group="learn_from_text")
@pytest.mark.asyncio
async def test_learn_from_text_performance(benchmark):
    """
    learn_from_text fonksiyonunun performansÄ±nÄ± test eder.

    Asenkron Ã§alÄ±ÅŸan bu fonksiyon, uzun bir metinden bilgi Ã¶ÄŸrenme sÃ¼recini Ã¶lÃ§er.
    """
    async def run():
        await learn_from_text("user_perf", "deneme metni " * 100)

    benchmark(run)


@pytest.mark.asyncio
async def test_rate_limiter_performance(monkeypatch, benchmark):
    """
    RedisRateLimiter sÄ±nÄ±fÄ±nÄ±n allow metodunun performansÄ±nÄ± test eder.

    Redis yapÄ±sÄ± mock'lanmÄ±ÅŸtÄ±r. 100 istek Ã¼zerinde hÄ±z sÄ±nÄ±rlama Ã¶lÃ§Ã¼lÃ¼r.
    """
    mock_redis = MagicMock()
    monkeypatch.setattr("learning.redis_client", mock_redis)
    mock_redis.pipeline.return_value.__enter__.return_value.execute.return_value = [None, None, 1, None]

    limiter = RedisRateLimiter("perf_test", rate=10, per=1)

    def call_allow():
        for _ in range(100):
            limiter.allow("user1")

    benchmark(call_allow)
