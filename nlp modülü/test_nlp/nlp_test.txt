import pytest
import os
import time
import concurrent.futures
from unittest.mock import patch
from nlp import estimate_token_count, safe_truncate_nlp

@pytest.mark.parametrize(
    "text, expected_min_tokens",
    [
        ("Merhaba dÃ¼nya!", 2),
        ("", 0),
        (" ", 0),
        ("Merhaba dÃ¼nya! " * 1000, 20_000),
        ("ğŸ˜ŠğŸ‘ğŸ½", 3),
    ]
)
def test_estimate_token_count(text, expected_min_tokens):
    count = estimate_token_count(text)
    assert isinstance(count, int), "Token sayÄ±sÄ± int tipinde olmalÄ±."
    assert count >= 0, "Token sayÄ±sÄ± negatif olmamalÄ±."
    if text.strip():
        assert count >= expected_min_tokens, f"Token sayÄ±sÄ± beklenen minimum {expected_min_tokens}'den az."

@pytest.mark.parametrize(
    "text",
    [
        "",                    # BoÅŸ string
        "    ",                # Sadece boÅŸluk
        "\t\n\r",              # Kontrol karakterleri
        "kelime\tkelime\nkelime",  # Tab ve newline iÃ§eriyor
        "A" * 10000,           # Ã‡ok uzun tek karakter
        "\u200b" * 100,        # Zero-width space karakterleri
        "kelime" * 1000 + "\x00",  # Null karakter iÃ§eriyor
    ]
)
def test_estimate_token_count_edge_cases(text):
    count = estimate_token_count(text)
    assert isinstance(count, int)
    assert count >= 0

@pytest.mark.parametrize(
    "text, max_tokens",
    [
        ("kelime kelime\tkelime\nkelime", 3),
        ("", 1),
        ("   ", 1),
        ("\t\n\r", 2),
        ("A" * 10000, 5),
        ("\u200b" * 50, 3),
    ]
)
def test_safe_truncate_nlp_edge_cases_with_special_chars(text, max_tokens):
    truncated = safe_truncate_nlp(text, max_tokens=max_tokens)
    assert isinstance(truncated, str)
    count = estimate_token_count(truncated)
    assert count <= max_tokens


@pytest.mark.parametrize(
    "text, max_tokens, expect_truncated",
    [
        ("KÄ±sa cÃ¼mle.", 100, False),
        ("Bu Ã§ok uzun bir metindir ve kesilecek.", 5, True),
        ("", 10, False),
        ("Token sÄ±nÄ±rÄ±nda test", 3, True),
        ("A" * 50, 1, True),
    ]
)
def test_safe_truncate_nlp_behavior(text, max_tokens, expect_truncated):
    truncated = safe_truncate_nlp(text, max_tokens=max_tokens)
    assert isinstance(truncated, str), "DÃ¶nÃ¼ÅŸ tipi string olmalÄ±."
    if expect_truncated:
        assert truncated != text, "Metin kesilmeli ama farklÄ± kalmalÄ±."
        assert len(truncated) > 0, "Kesilen metin boÅŸ olmamalÄ±."
    else:
        assert truncated == text, "Metin kesilmemeli."

def test_safe_truncate_nlp_edge_cases():
    truncated = safe_truncate_nlp("Deneme", max_tokens=0)
    assert truncated == "", "max_tokens=0 ise boÅŸ string dÃ¶nmeli."
    
    with pytest.raises(ValueError):
        safe_truncate_nlp("Deneme", max_tokens=-1)

def test_estimate_token_count_non_string_input():
    for invalid_input in [None, 123, 12.5, [], {}, ()]:
        with pytest.raises(TypeError):
            estimate_token_count(invalid_input)

def test_estimate_token_count_performance_with_tolerance():
    text = "Merhaba dÃ¼nya! " * 10000
    start_time = time.time()
    count = estimate_token_count(text)
    duration = time.time() - start_time
    assert isinstance(count, int)
    assert duration < 2.0, f"estimate_token_count Ã§ok yavaÅŸ Ã§alÄ±ÅŸÄ±yor: {duration:.2f}s"

    # Performans limiti dÄ±ÅŸarÄ±dan ayarlanabilir, default 2 saniye
    max_duration = float(os.getenv("PERF_TEST_TIMEOUT", "2.0"))
    print(f"[PERF TEST] estimate_token_count Ã§alÄ±ÅŸma sÃ¼resi: {duration:.2f}s (limit: {max_duration}s)")
    assert duration < max_duration, f"estimate_token_count Ã§ok yavaÅŸ Ã§alÄ±ÅŸÄ±yor: {duration:.2f}s"

@pytest.mark.parametrize(
    "text, max_tokens, expect_truncated",
    [
        ("Token sÄ±nÄ±rÄ±nda", 1, True),
        ("Tek kelime", 2, False),
        ("A", 1, False),
        ("", 1, False),
        ("Test metni", 0, True),
    ]
)
def test_safe_truncate_nlp_additional_edges(text, max_tokens, expect_truncated):
    truncated = safe_truncate_nlp(text, max_tokens=max_tokens)
    assert isinstance(truncated, str)
    if expect_truncated:
        assert truncated != text or truncated == "", "Metin kesilmeli."
    else:
        assert truncated == text, "Metin kesilmemeli."

def test_safe_truncate_nlp_invalid_max_tokens_behavior():
    with pytest.raises(ValueError):
        safe_truncate_nlp("Deneme", max_tokens=-5)

def test_estimate_token_count_invalid_input_type():
    for invalid in [None, 123, 5.6, [], {}, set()]:
        with pytest.raises(TypeError):
            estimate_token_count(invalid)

def test_concurrent_calls():
    texts = ["Bu bir test metnidir."] * 1000
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(estimate_token_count, t) for t in texts]
        results = [f.result() for f in futures]
    assert all(isinstance(r, int) for r in results), "TÃ¼m sonuÃ§lar int olmalÄ±."

@patch("nlp.tiktoken")
def test_estimate_token_count_with_mocked_tiktoken_varied_behavior(mock_tiktoken):
    class DummyEncoder:
        def encode(self, text):
            return [1] * (len(text.split()) * 2)
    mock_tiktoken.encoding_for_model.return_value = DummyEncoder()

    text = "Bu bir deneme metni"
    count = estimate_token_count(text)
    expected = len(text.split()) * 2
    assert count == expected, f"Mock kullanÄ±nca {expected} token sayÄ±lmalÄ±, {count} bulundu."

    class ErrorEncoder:
        def encode(self, text):
            raise RuntimeError("Encode hatasÄ±")
    mock_tiktoken.encoding_for_model.return_value = ErrorEncoder()

    with pytest.raises(RuntimeError):
        estimate_token_count("Hata testi")

@patch("nlp.tiktoken")
def test_estimate_token_count_mock_various_behaviors(mock_tiktoken):
    class DummyEncoderSuccess:
        def encode(self, text):
            return [1] * (len(text.split()) * 3)  # 3 kat token dÃ¶ndÃ¼r

    class DummyEncoderEmpty:
        def encode(self, text):
            return []

    class DummyEncoderNone:
        def encode(self, text):
            return None

    class DummyEncoderError:
        def encode(self, text):
            raise RuntimeError("Mock encode error")

    # BaÅŸarÄ±lÄ± durum
    mock_tiktoken.encoding_for_model.return_value = DummyEncoderSuccess()
    text = "Bu bir test metni"
    count = estimate_token_count(text)
    expected = len(text.split()) * 3
    assert count == expected, f"BaÅŸarÄ±lÄ± mock ile {expected} token bekleniyor, {count} geldi."

    # BoÅŸ liste dÃ¶nmesi
    mock_tiktoken.encoding_for_model.return_value = DummyEncoderEmpty()
    count = estimate_token_count(text)
    assert count == 0, "BoÅŸ encode sonucu token sayÄ±sÄ± 0 olmalÄ±."

    # None dÃ¶nmesi (hatalÄ± kullanÄ±m)
    mock_tiktoken.encoding_for_model.return_value = DummyEncoderNone()
    with pytest.raises(TypeError):
        estimate_token_count(text)

    # Hata fÄ±rlatmasÄ±
    mock_tiktoken.encoding_for_model.return_value = DummyEncoderError()
    with pytest.raises(RuntimeError):
        estimate_token_count(text)
# ... diÄŸer test fonksiyonlarÄ± ...

@pytest.mark.parametrize(
    "text",
    [
        "Ä°stanbul'da gÃ¼zel bir gÃ¼n â˜€ï¸ğŸŒ³",
        "ä¸­æ–‡è¾“å…¥æµ‹è¯•",
        "ğŸ‘ğŸ½ğŸ”¥ğŸ’¯",
        "Emoji test ğŸ˜ŠğŸš€âœ¨",
        "ğ“£ğ“®ğ”ğ“½ ğ”€ğ“²ğ“½ğ“± ğ“¼ğ“½ğ”‚ğ“µğ“®ğ“­ ğ“¬ğ“±ğ“ªğ“»ğ“¼",
        "à¤…à¤šà¥à¤›à¤¾ à¤¦à¤¿à¤¨ à¤¹à¥ˆ",
        "Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…",
        "Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚ĞµĞºÑÑ‚Ğ°",
    ]
)
def test_estimate_token_count_unicode_and_special_chars(text):
    count = estimate_token_count(text)
    assert isinstance(count, int), "Token sayÄ±sÄ± int olmalÄ±."
    assert count > 0, "Token sayÄ±sÄ± pozitif olmalÄ±."

@pytest.mark.parametrize(
    "text, max_tokens",
    [
        ("Ä°stanbul'da gÃ¼zel bir gÃ¼n â˜€ï¸ğŸŒ³", 5),
        ("ä¸­æ–‡è¾“å…¥æµ‹è¯•", 3),
        ("ğŸ‘ğŸ½ğŸ”¥ğŸ’¯", 2),
        ("Emoji test ğŸ˜ŠğŸš€âœ¨", 4),
        ("ğ“£ğ“®ğ”ğ“½ ğ”€ğ“²ğ“½ğ“± ğ“¼ğ“½ğ”‚ğ“µğ“®ğ“­ ğ“¬ğ“±ğ“ªğ“»ğ“¼", 6),
        ("à¤…à¤šà¥à¤›à¤¾ à¤¦à¤¿à¤¨ à¤¹à¥ˆ", 3),
        ("Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…", 4),
        ("Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚ĞµĞºÑÑ‚Ğ°", 5),
    ]
)
def test_safe_truncate_nlp_unicode(text, max_tokens):
    truncated = safe_truncate_nlp(text, max_tokens=max_tokens)
    assert isinstance(truncated, str), "Truncate sonucu string olmalÄ±."
    count = estimate_token_count(truncated)
    assert count <= max_tokens, f"Truncate sonrasÄ± token sayÄ±sÄ± max_tokens'dan fazla: {count} > {max_tokens}"



@pytest.mark.parametrize(
    "text",
    [
        "Ä°stanbul'da gÃ¼zel bir gÃ¼n â˜€ï¸ğŸŒ³",
        "ä¸­æ–‡è¾“å…¥æµ‹è¯•",
        "ğŸ‘ğŸ½ğŸ”¥ğŸ’¯",
        "Emoji test ğŸ˜ŠğŸš€âœ¨",
        "ğ“£ğ“®ğ”ğ“½ ğ”€ğ“²ğ“½ğ“± ğ“¼ğ“½ğ”‚ğ“µğ“®ğ“­ ğ“¬ğ“±ğ“ªğ“»ğ“¼",
    ]
)

def test_safe_truncate_nlp_large_text_truncation():
    large_text = "kelime " * 100_000
    max_tokens = 50

    truncated = safe_truncate_nlp(large_text, max_tokens=max_tokens)
    count = estimate_token_count(truncated)
    assert count <= max_tokens, "Truncate edilen metin max_tokens sÄ±nÄ±rÄ±nÄ± aÅŸmamalÄ±."
    assert isinstance(truncated, str), "Truncate sonucu string olmalÄ±."
    assert len(truncated) < len(large_text), "Truncate edilen metin orijinalden kÄ±sa olmalÄ±."

def test_safe_truncate_nlp_large_input():
    large_text = "kelime " * 100000
    truncated = safe_truncate_nlp(large_text, max_tokens=500)
    assert isinstance(truncated, str)
    assert len(truncated) > 0
    token_count = estimate_token_count(truncated)
    assert token_count <= 500, f"Truncated token sayÄ±sÄ± max_tokens'dan fazla: {token_count} > 500"


@pytest.mark.asyncio
def test_estimate_token_count_sync_in_async_context():
    text = "Merhaba sync dÃ¼nya!"
    count = estimate_token_count(text)
    assert isinstance(count, int)
    assert count > 0

@pytest.mark.asyncio
def test_safe_truncate_nlp_sync_in_async_context():
    text = "Bu uzun bir metindir ve kesilecek."
    truncated = safe_truncate_nlp(text, max_tokens=5)
    assert isinstance(truncated, str)
    # Token sayÄ±sÄ±nÄ± kontrol et
    from nlp import estimate_token_count
    count = await estimate_token_count(truncated)
    assert count <= 5
